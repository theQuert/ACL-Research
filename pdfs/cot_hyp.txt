"We elaborate on our framework in three subsections: multiple instance learning, building toxicity dataset, and MIL-Decoding for Integrated Detoxification. In MIL, the goal is to predict a label y for a given set of instances from a bag X = {x1, x2, ..., xn}. In our setting, instances are tokens in context and the bag is the set of all tokens for each given sentence exists as. We fine-tuned an MIL-model on a binary classification task to predict the toxicity at sentence-level, and the toxicity of each token in context as well. We also make an attempt as a ternary generation: positive, negative, and neutral. Our MIL model handles both binary and ternary generation, and we implemented it with pre-trained RoBERTa-base (Liu et al., 2019). \n\nOur MIL model works like two parallel decoders, the first decoder generates tokens only when the token is not toxic, and the second decoder is responsible for generating toxic tokens. For each token, we learn the probability of it being toxic as a binary classification task. For reduction operation, we calculated the overall toxicity by aggregating token-level toxicity with max pooling. \n\nExpanding on earlier work on MIL technology sentiment analysis (Wang and Wan, 2018; Angelidis and Lapata, 2018), we crafted an MIL-detoxifier on the basis of the RoBERTa-based language model to steer generated text away from toxicity. Selecting our generator model as the RoBERTa-base (Liu et al., 2019), we generate tokens in an autoregressive fashion. When generating the i-th token, we calculate the toxicity distribution for the next token and interpolate the original distribution from the language model with the toxicity distribution. This way, the MIL-detoxifier discourages the generator from producing tokens with high toxicity scores. The integrated MIL-Decoding method realizes detoxification of a language model by integrating our MIL model into the decoding stage.\n\nStep-by-step, the process can be outlined as follows: Once a token x1 is generated ,its toxicity context is obtained as x1's representation from MIL-model. Then, we run MIL-model again to get the toxicity context of next token. Lastly, the log-probability log P is obtained from LM, and the toxicity log-probability log P toxic is obtained from MIL-model. The final score of token x combined these two scores. \n\nFor the toxicity training dataset, we curated a dataset with fine-grained toxicity labels for every token in its context. To this end, we made use of publicly available toxicity-annotated datasets. The goal here is not to make a perfectly accurate dataset, rather we aimed at creating a corpus with as many discernible toxicity class labels as possible. \n\nHuman evaluation of the results showed that our MIL-Decoding model outperforms other baselines in detoxification, with only minor effects on fluency aspect of the generated text. Due to the structure of our MIL-Decoding model, we managed to retain the language generation properties of the pre-training model while minimizing the occurrence of toxicity at token level."
'1. Hallucination Detection: The central idea is to exploit the intrinsic characteristics of the machine translation model, without any external tools. Specifically, they use sequence log probability to identify hallucinations. Each translated sentence\'s sequence log-probability score is obtained from the trained translation model, reflecting the model\'s own certainty in generating the translation. Instances flagged by the sequence log probability often correlate with instances of hallucination.\n\n2. Severity Classification: Once potential hallucinations are detected, the system classifies them based on severity according to a predefined taxonomy: fully detached hallucinations (the whole content is not supported by the source) and strongly, but not fully, detached hallucinations (a significant proportion of output is not supported by the source). This is done by leveraging self-attention scores, which provide insight into which target words the model deems important when generating a particular output word.\n\n3. Hallucination Mitigation: For mitigation, the system devises a method that attempts to fix existing hallucinations at test time. This involves iterative beam decoding, a method that iteratively generates new translations while penalizing phrases that were part of the hallucinated content in previous iterations.\n\n*These solutions seem to address the problem presented in the abstract by using only the model\'s features and internal log probabilities to detect and potentially correct "hallucinations" or errors that arise and seem unrelated to the source text. Therefore, these methods can be deemed valid.*\n\n4. Sentence Similarity Tool: As a further improvement to internal model workings, the method integrates an external sentence similarity tool that compares the translated sentences to the original source sentences. Sentence pairs that show significant discrepancy in terms of content can be identified as probable hallucinations.\n\n5. Token Level Attention: The model is fine-tuned to pay greater attention to the alignment of tokens from the source sentence to target sentence. This method is expected to improve the quality of translation by ensuring more accurate alignment and translation of tokens.\n\n6. Enhanced Training: For hallucination mitigation, the model is further trained on a supplemented dataset that includes both hallucinated translations and their corresponding corrections. Providing direct examples of hallucinated outputs coupled with their proper corrections can help the model learn the patterns of hallucination occurrences and rectifications.'
"1) Dialogue History Embedding: For each dialogue, mark each utterance with its turn and speaker and extract its content as input. Compose a positional embedding system to account for the possibly complex dialogue history. \n\n2) Addressee Prediction Module: Predict the addressee of the next utterance using the dialogue history embedding. This can be implemented using a multiclass classification approach, with each class representing a potential speaker in the dialogue. \n\n3) Response Generation Module: Generate the response based on the dialogue history embedding and the predicted addressee. This response needs to be coherent and relevant to the conversation. A typical encoder-decoder architecture can be used for this stage. \n\n4) Fine-tuning and Evaluation: Fine-tune the model on a large multi-party dialogue corpus. After the model is fine-tuned, evaluate the model's performance using standard dialogue evaluation metrics like BLEU, METEOR, and ROUGE scores. \n\n5) Iterative EM Updating: Initialize the EM approach using known labelled data. In the E-step, predict on the full corpus to derive soft labels. In the M-step, use the expected labels to retrain the model. Continue iteratively until convergence, with the final parameters determined as the maximization or distribution of expected labels. \n\nThese methods aim to address the challenges in multi-party dialogue response generation by predicting potential speakers (addressees) in the conversation and generating relevant responses. Distributing the data in an iterative way allows the latent structure of conversations to emerge. The approach is supported by a theoretically and data-driven construction of the dialogue history embeddings, which incorporate important characteristics such as speaker and dialogue turns. This can improve the coherence and relevancy of the translated dialogue responses, even in complex or multi-party dialogues."
"In order to detoxify the language model, MIL-Decoding introduces a token-level detoxification control framework. Four steps can be identified in this method:\n\n1. Multiple Instance Learning (MIL) Model Training: This involves training an MIL model on a toxicity-annotated corpus. The model is designed to estimate the toxicity level of each token within its context. The training data comprises bags (i.e., texts) with binary labels indicating the presence or absence of toxicity.\n\n2. Token-Level Detoxification Control: MIL-Decoding interpolates the language model with the trained MIL network, resulting in more controlled text generation. For each potential token, the MIL network is applied to predict its toxicity within the existing context. These token-level toxicity predictions form a toxicity distribution over next tokens.\n\n3. Inference Decoding: The final token to be generated is selected based on both the original language model's distribution and the estimated toxicity distribution. Existing greedy or beam-search inference methods, thus, are adapted for this purpose.\n\n4. Evaluation: The results from MIL-Decoding are evaluated through automatic metrics such as BLEU, ROUGE, and PPL scores along with human evaluation techniques. Comparisons are made with other detoxification baselines to ensure the solution's effectiveness and minimal effect on the fluency of the generated text.\n\nThis method provides contextual control over the toxicity, ensuring text output that aligns with safe and acceptable standards without having any significant negative impact on fluency. This approach is intuitive in the sense that it allows better alignment between sentence semantics and the toxicity of individual tokens within the sentence."
"Our approach, hereby termed Subset kNN-MT, aims to improve the decoding speed of the kNN-MT model by introducing two primary modification strategies. Firstly, rather than searching for neighbor target tokens from the entire corpus, our model searches within a smaller subset that is defined as the set of neighbor sentences of the input sentence involved. This approach lessens the computational burden substantially yet ensures accuracy by only considering relevant neighboring sentences.\n\nSecondly, we implement an efficient distance computation technique suitable for subset neighbor searches using a lookup table. Specified distances between sentences in the data store and the target tokens are precomputed and stored, thereby significantly reducing the time required for distance computation during real-time decoding.\n\nIn combination, these two strategies help expedite the decoding process without compromising on the translation accuracy. We validate our approach by benchmarking its performance against the original kNN-MT model in terms of both decoding speed and BLEU score. Our subset kNN-MT exhibited 132.2 times faster decoding and a 1.6 point increase in BLEU score across tasks in the WMT'19 De-En translation task as well as in domain adaptation tasks in De-En and En-Ja."
"1. Data Collection and Preparation: Collect high-quality documents from verified sources. In this case, we focus on sources supporting the 16 African Languages in consideration. Since the quality of the documents is crucial, additional measures to ensure their credibility and relevance are instituted. Special validators can be utilized to audit the document sources. \n\n2. Languages Supported Identification: This process involves identifying and grading the quality of languages supported by both the new dataset and the existing one that the new dataset is being compared with. This enables a better understanding of the improvements made in supporting low-resource languages.\n\n3. Pre-training using Multilingual T5: The next step involves pretraining a new T5-based Language Model (LM) on the collected dataset. This gives a general-purpose LM that can then be fine-tuned for specific tasks.\n\n4. Model Evaluation: The final step involves evaluating the new model against the existing models. This includes benchmarking the new model's performance on multiple downstream tasks such as Cross-lingual QA evaluation, and comparing with previous models to highlight the improvements in model performance. \n\nPossible further improvements include expanding the data curation process to include more languages and diversifying the sources of documents to cover a wider scope of the languages. Also, continued refinement of the model's architecture can help improve its performance on downstream tasks."
'We propose an iterative feedback-based learning process aimed at improving an extractive question answering (QA) system over time. This process involves user-system interaction, where users ask questions and receive model-provided answers. Upon receiving an answer, the user provides feedback which is then used to update the model.\n\nThe first step involves the initialization of a strong pre-trained model on a supervised extractive QA task. Post-initialization, users interact with the system to ask questions and receive answers. Each interaction is logged and consists of a dialogue, document, user question, model-predicted answer and user feedback.\n\nFeedback is obtained in the form of a three-level rating scale - correct, partially correct, and wrong. Each rating corresponds to a numerical reward, which is utilized as the learning signal for our model. The reward mapping for correct, partially correct, and wrong is +1, 0, and -1 respectively.\n\nWe steer away from comparisons of model-predicted answers to actual gold-standard answers due to the limited availability of such gold-standard references in a real-world scenario. Instead, we use learned reward models combined with counterfactual reasoning methods in a contextual bandit learning framework.\n\nIn order to update the QA model based on the collected feedback, we utilize a selection of training instances from logged interactions that have reward annotations. The model is then fine-tuned on these instances through min-loss training with the logged propensity weights.\n\nImportantly, we alternate between the period of model serving (interaction and feedback logging) and model updating (re-training the model with the most recent feedback). This allows us to simulate a practical scenario of user interaction unfolding over time while creating room for model improvement from fresh user feedback.\n\nThis approach offers several advantages. Not only does it offer the potential for rapid and significant system improvement with minimal feedback, but it also accommodates varied data scenarios. By leveraging user feedback, we can additionally explore domain adaptation potential.\n\nOn another note, the simplicity of the feedback mechanism employed (three-option rating scale) can be effectively integrated in real-world systems, thereby enabling practical system deployment with continual learning capabilities. \n\nWe believe that this approach provides a robust framework for improving extractive QA systems via continual learning from human user feedback in a broad range of scenarios. We also expect our findings to stimulate wider interest in the relatively understudied area of continual learning from user feedback in the context of NLP tasks.'
'To begin with, the mQG model is built based on a transformer architecture, which is further fine-tuned on a narrative question dataset, while incorporating additional losses. The model aims to generate multiple, mutually dissimilar questions with this training process. The first step in the proposed method is the question generation. Starting off with an initial question, more contextually related questions are sequentially generated. Each subsequent newly generated question is referenced against the previous questions to ensure diversity among the generated questions. \n\nNext, to ensure the diversity of the generated questions, a Diversity Maximization Loss (DML) is employed. DML is designed to increase the semantic distance between the last question generated and the previous ones. Therefore, each question differs from the others, maximizing the semantic diversity.  \n\nFurthermore, in order to generate questions with high quality, Maximum Question Similarity Loss (MQS) is introduced. MQS is used upon the set of questions to increase the semantic similarity between the newly generated question and context while decreasing the similarity between the new question and previous ones. This process ensures that all questions are contextually relevant and diverse from each other. \n\nFinally, after the question generation phase, an answerability evaluation comes into play. An Answerability Evaluation Model (AEM) is introduced to determine whether the generated question is answerable from the context, whether it has an explicit or implicit answer present in the context, or if it is unanswerable. AEM is trained to label these categories, following which, the generated questions are ranked based on their answerability and quality. \n\nIn summary, this unique combination of features in our method - diversity maximizing loss, maximum question similarity loss, and answerability evaluation model, leads to an effective process for generating multiple, diverse, quality, and answerable questions from a given context, thereby addressing the limitations and shortcomings of the existing QG techniques in the domain. \n\nThis method could be improved upon by enhancing the semantic understanding of the system especially for unanswerable questions or introducing more sophisticated mechanisms to adapt to different context scenarios.'
"Our proposed method begins with defining and identifying span representations. We use a sliding window to create all possible spans in a sentence and represent each span using a dual-channel mechanism. In the first channel, we use a novel syntactic span generation algorithm, which leverages the inherent grammatical structure of the sentence and the dependencies among words to generate span candidates that are syntactically coherent and meaningful. The second channel operates in the semantic domain, where part-of-speech (POS) information is utilized to generate span candidates. The idea here is to exploit the fact that aspects and opinions in a review usually conform to certain POS patterns. \n\nOnce we have created our dual-channel span representations, we apply a series of prediction layers. The purpose of the prediction layer is three-fold - to predict which spans in the sentence correspond to aspect terms, which correspond to opinion terms and the sentiment polarity of each span. The double-layer BiLSTM layer is utilized to capture the interaction between these two channels and together they contribute to the final span representations.\n\nFor this, we use two separate BiLSTM layers - the first one operates at the span level, where the input to the layer is the dual-channel span representations. It aims to encode the interaction of syntactic and POS semantic information within each span. The second LSTM layer operates at the sentence level, wherein the outputs of the first BiLSTM layer are used as input. This helps in encoding global interaction between different spans in the sentence. \n\nFinally, we calculate a context-weighted representation for each span. The span representations and the context-weighted representations are then combined to predict the three objectives - aspect terms, opinion terms, and sentiment polarity. \n\nTo assess our model's performance, we conduct extensive experiments on two public aspect sentiment triplet extraction (ASTE) datasets and compare the results with several state-of-the-art systems. Our method significantly outperforms other methods, demonstrating that the dual-channel span generation method can effectively and efficiently extract meaningful spans and accurately perform the ASTE task. \n\nWhile the span-based methods usually suffer from high computational cost and excessive noise, our proposed method effectively mitigates these issues by narrowing down the span candidates with linguistic priors, hence able to model the syntactic and POS patterns observed in aspects and opinions, and successfully improve the performance on the ASTE task."
"In this work, we propose a novel method that leverages scene graph-based decomposition and enhancement frameworks, along with coarse-to-fine contrastive learning objectives, to improve the compositional reasoning capabilities of contrastively trained vision-language models. \n\nFirstly, we draw scene graphs from textual input to mirror the scene graphs of corresponding images. This involves identifying objects, attributes, and relationships from the textual content and converting them into a structured graph representation comparable to the image's scene graph. \n\nWe then propose a graph decomposition and augmentation framework aimed at aligning contextual complexity between images and text sentences. This step involves identifying and eliminating inconsistencies or imbalances in complexity between the corresponding scene graphs of images and text. \n\nWe introduce a coarse-to-fine contrastive learning objective that enables the model to map complex sentences to the same image while concurrently understanding and identifying intricate relations within the image's content. This learning objective facilitates the model in progressively recognizing and understanding relations, attributes, and objects from coarser to finer definitions.\n\nTo further improve the model's understanding of attribute binding and relations, we introduce novel techniques for negative mining in the scene graph space. These techniques work by identifying and isolating negative examples or outliers in attribute binding and relations within the scene graph, further strengthening the model's ability to make correct attribute-object bindings and to understand relations between objects.\n\nConsequently, the proposed method demonstrates significant improvement in multiple benchmarks, such as attribute binding, relation understanding, systematic generalization, and productivity. This results in a more compositionally capable vision-language model that excels not only on these specific tasks but also performs competently on general multimodal tasks."