"In order to detoxify the language model, MIL-Decoding introduces a token-level detoxification control framework. Four steps can be identified in this method:\n\n1. Multiple Instance Learning (MIL) Model Training: This involves training an MIL model on a toxicity-annotated corpus. The model is designed to estimate the toxicity level of each token within its context. The training data comprises bags (i.e., texts) with binary labels indicating the presence or absence of toxicity.\n\n2. Token-Level Detoxification Control: MIL-Decoding interpolates the language model with the trained MIL network, resulting in more controlled text generation. For each potential token, the MIL network is applied to predict its toxicity within the existing context. These token-level toxicity predictions form a toxicity distribution over next tokens.\n\n3. Inference Decoding: The final token to be generated is selected based on both the original language model's distribution and the estimated toxicity distribution. Existing greedy or beam-search inference methods, thus, are adapted for this purpose.\n\n4. Evaluation: The results from MIL-Decoding are evaluated through automatic metrics such as BLEU, ROUGE, and PPL scores along with human evaluation techniques. Comparisons are made with other detoxification baselines to ensure the solution's effectiveness and minimal effect on the fluency of the generated text.\n\nThis method provides contextual control over the toxicity, ensuring text output that aligns with safe and acceptable standards without having any significant negative impact on fluency. This approach is intuitive in the sense that it allows better alignment between sentence semantics and the toxicity of individual tokens within the sentence."