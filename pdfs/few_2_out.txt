To bridge the gaps of previous research, we identify comprehensive controlling aspects from the translatology literature, propose prompt-based solutions for each aspect, and explore more effective foundation models and adaptation methods.Are there some universal rules that we can adopt to obtain singable translations? We ﬁrst rule out some prospective answers. Strictly keeping the positions of stressed syllables (Ghazvininejad et al., 2018) is inappropriate as stressing certain syllables is the property of stress-timed language. In contrast, syllable-timed languages, e.g., French and Mandarin, give syllables approximately equal prominence. Aligning the characters’ tone with the melody (Guo et al., 2022) is also not a good choice. On the one hand, this rule only applies to tonal languages. On the other hand, this rule is increasingly being ignored by the majority of songs composed in recent decades (Gao, 2017), indicating the marginalized importance of the intelligibility of songs, especially in pop 2 .To achieve a comprehensive and languageindependent method, we deﬁne “singable translation” as following the “Pentathlon Principle” from (Low, 2003): that quality, singable translations are obtained by balancing ﬁve aspects—singability, rhythm, rhyme, naturalness, and sense. Table 1 lists these aspects and corresponding requirements, and how we actualize them in our model. Particularly, we identify (1)–(3) as the controlling aspects of our model and realize them with prompt-based control, while (4) and (5) are achieved from the perspectives of adaptation and pretraining.We deﬁne the task that is tackled in this paper, singable and controllable lyric translation, as follows: given one line of lyrics X in a source language L src and a set of desired properties of outputsentence { l tgt , r tgt , b tgt } , generating text translation Y in target language L tgt for X by modeling P(Y | X, l tgt , r tgt , b tgt ), where (1) the total number of syllables of sentence Y to be precisely equal to length constraint l tgt ; (2) Y ends with a word that is in the same rhyme type of rhyme constraint r tgt ; (3) Y has word boundaries—the positions between two consecutive syllables that belong to different words—in all locations indicated in necessary word boundary constraint b tgt ; (4) Y is of maximal naturalness, and is ﬁdelity to the sense of X.Two types of special tokens are constructed as prompts for sentence-level control. For each sentence, the length and rhyme prompts are single token len_i and rhy_j, indicating the desired number of syllables of the output is i and that the desired end-rhyme type of output is j. The prompt for necessary word boundaries is a sequence of special tokens, bdr = { bdr_0, bdr_1 } len_i , indicating the desired word boundary positions. During the training process, these prompts are derived from the analysis of target-side sentences, guiding the model towards generating sentences with corresponding properties. Consequently, there is no need for accompanying music during training. At the inference stage, prompts can be crafted from either music or source-side sentences. For an overview of the system workﬂow, please refer to Figures 3b and 3c.We conducted a group of experiments to test three different prompt methods to determine the best one for each control aspect. They are (1) Encpref: prompts are injected into the encoder’s input as a preﬁx. (2) Dec-pref: prompts are injected into the decoder’s input as a preﬁx. (3) Dec-emb: prompts are embedded into a vector and added toward the decoder’s input.Intra-word pause is a typical disﬂuency pattern of beginning language learners (Franco et al., 1998). However, improperly translated lyrics usually con-tain multi-syllable words that lies across musical pauses, as the blue box in Figure 2, so that the performer has to make awkward intra-word pauses while singing (Guo et al., 2022), causing a drop in pronunciation acceptability. Besides, we observe that positioning highlighted music notes, such as high notes or downbeats, as the orange box in Figure 2, onto a multi-syllable word’s second or later syllables can bring similar adverse effects due to abrupt changes of pitch and tension 3 .We address these issues by carefully designing the placement of word boundaries in outputs, i.e., the points between two consecutive syllables that are from different words. Our aim is to ensure that word boundaries align precisely with the boundaries in music, i.e., the melody boundaries, which occur at musical pauses and before highlighted notes (the blue and orange boxes in Figure 2). In this way, we achieve higher compatibility between the output sentences and the accompanying music, enhance the ﬂuency and consistency of pronunciation during singing, and hence lead to the gain of singability.This solution is achieved by prompt-based word boundary control. We use the prompt bdr to represent melody boundary positions, indicating necessary word boundary positions. bdr is a sequence of special tokens, and each token corresponds to one syllable in the output. There are two types of special interior tokens: bdr_1 and bdr_0, representing after the corresponding syllable “there should be a word boundary” and “we do not care if thereis a boundary”, respectively. At test time, bdr is obtained from accompanying music and serves as additional inputs. A well-trained word-boundaryaware model can hence place word boundaries at the desired positions to achieve better music–lyric compatibility. For locations where bdr_0 is present (“don’t care”), the translation model operates unconstrained, maximizing translation naturalness. During training, length and rhyme prompts can be obtained directly from the target sentences in the training samples, but not again for necessary word boundary prompts because they have to be obtained from accompanying music which is absent in training. Nevertheless, we offer a solution: we randomly sample from all actual word boundary positions from the target-side text and use this sampled subset as “pseudo ground truth” to construct bdr for training.We imitate the process of human translators translating texts in rhyme: translating the last word ﬁrst, and from back to front, which is an old trick to keep rhyming patterns from being forced (Low, 2003). We implement this by reverse-order decoding. During ﬁne-tuning with parallel data, we reverse the word order of target-side text while retaining the source-side text unchanged. This approach minimally changes the structure and workﬂow of off-the-shelf translation models.Controllability alone is not enough. For a given input sentence, the rhyming usually only looks good in certain rhyme types but appears forced in others (see Appendix C.2 for details). No matter how good the controllability is, the output quality will be severely damaged if an ill-ﬁtting rhyme prompt is provided by the user. To avoid such problems, we need to determine the most suitable end-rhyme for translating one sentence, and further one paragraph consisting of multiple sentences. Previous research left this problem unsolved. Fortunately, our reverse-order decoder simpliﬁes the rhyme ranking process. During training, we use an additional special token rhy_0 to nullify rhyme constraints for output. We achieve this by randomly converting a portion of each type of rhyme prompt to rhy_0 during training. At inference time, for a given source sentence X i and prompts l tgt , r tgt and b tgt , we ﬁrst use rhy_0 as the rhyme prompt to dothe ﬁrst step of reverse-order decoding to obtain the end-word probability distribution, where the v is the vocabulary size of the target language. Note that the p(w j ) not only indicates the end-word probability, but also predicts output text quality and the likelihood of satisfaction of length and word boundary constraints of the rhymeunconstrained model, from a greedy point of view. Intuitively, starting with tokens with low probabilities will pull down the corresponding beams’ scores and degrade the output quality. On the contrary, sentences with higher quality can be obtained by starting decoding with w j with higher p(w j ), and we achieve this by giving the model a rhyme prompt that guides it towards starting with such w j . We sum up the probability in Eq. 1 within each rhyme type to obtain the rhyme distribution of given inputs,where Rhy(·) is a map between a word or the endword of a sentence to its rhyme type, u is the number of rhyme types in the target language. For a certain rhyme type i, a higher p i value indicates a higher probability of successful rhyming and higher output quality, where f refers to the ﬁrst step of reverse-order decoding. We then use P(Rhy(Y)) as the rhyme ranking score of this paragraph to guide the rhyme selection.In-domain parallel data suffer from two issues. First, its amount is so limited that it is not comparable with general-domain data. Second, there are severe quality issues when target-side lyrics are translated by online communities, including wrong translation (Li, 2020), creative treason (Zhang, 2022), over-domestication (Xie and Lei, 2022), etc. To mitigate the issue of data quantity and quality, we seek help from target-side monolingual lyric data. Our approach involves incorporating back-translation (Sennrich et al., 2015) of targetside in-domain monolingual data to augment the parallel data for ﬁne-tuning. To demonstrate its effectiveness, we conduct a comparative study with the adaptation method in (Guo et al., 2022), which performs sentence-level denoising pretraining (Lewis et al., 2019) with in-domain data after general-domain pretraining. Taken together, these innovations form our ﬁnal control method, which we can apply to any foundation model. In the evaluation that follows, we instantiate our techniques with Multilingual BART (refer to Figure 3 for structure and workﬂow), producing the Singable Translation (Row 3) in Figure 1. Additional case studies are featured in Appendix C.