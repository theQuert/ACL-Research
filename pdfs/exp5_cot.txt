"Our approach, hereby termed Subset kNN-MT, aims to improve the decoding speed of the kNN-MT model by introducing two primary modification strategies. Firstly, rather than searching for neighbor target tokens from the entire corpus, our model searches within a smaller subset that is defined as the set of neighbor sentences of the input sentence involved. This approach lessens the computational burden substantially yet ensures accuracy by only considering relevant neighboring sentences.\n\nSecondly, we implement an efficient distance computation technique suitable for subset neighbor searches using a lookup table. Specified distances between sentences in the data store and the target tokens are precomputed and stored, thereby significantly reducing the time required for distance computation during real-time decoding.\n\nIn combination, these two strategies help expedite the decoding process without compromising on the translation accuracy. We validate our approach by benchmarking its performance against the original kNN-MT model in terms of both decoding speed and BLEU score. Our subset kNN-MT exhibited 132.2 times faster decoding and a 1.6 point increase in BLEU score across tasks in the WMT'19 De-En translation task as well as in domain adaptation tasks in De-En and En-Ja."