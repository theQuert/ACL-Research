"In this work, we propose a novel method that leverages scene graph-based decomposition and enhancement frameworks, along with coarse-to-fine contrastive learning objectives, to improve the compositional reasoning capabilities of contrastively trained vision-language models. \n\nFirstly, we draw scene graphs from textual input to mirror the scene graphs of corresponding images. This involves identifying objects, attributes, and relationships from the textual content and converting them into a structured graph representation comparable to the image's scene graph. \n\nWe then propose a graph decomposition and augmentation framework aimed at aligning contextual complexity between images and text sentences. This step involves identifying and eliminating inconsistencies or imbalances in complexity between the corresponding scene graphs of images and text. \n\nWe introduce a coarse-to-fine contrastive learning objective that enables the model to map complex sentences to the same image while concurrently understanding and identifying intricate relations within the image's content. This learning objective facilitates the model in progressively recognizing and understanding relations, attributes, and objects from coarser to finer definitions.\n\nTo further improve the model's understanding of attribute binding and relations, we introduce novel techniques for negative mining in the scene graph space. These techniques work by identifying and isolating negative examples or outliers in attribute binding and relations within the scene graph, further strengthening the model's ability to make correct attribute-object bindings and to understand relations between objects.\n\nConsequently, the proposed method demonstrates significant improvement in multiple benchmarks, such as attribute binding, relation understanding, systematic generalization, and productivity. This results in a more compositionally capable vision-language model that excels not only on these specific tasks but also performs competently on general multimodal tasks."