'METHOD: \n\n1. Expectation-Maximization (EM) Approach: The abstract mentions the lack of annotated addressee labels in multi-party dialogue datasets as a challenge for pre-training response generation models. To tackle this obstacle, the proposed method is to use an Expectation-Maximization (EM) approach. This approach iteratively performs expectation steps to generate addressee labels and maximization steps to optimize a response generation model. By iteratively updating the addressee labels and training the model, the EM approach can overcome the data scarcity issue and effectively pre-train response generation models for multi-party dialogues.\n\n2. Utilizing Large Unlabeled Corpora: In the related work section, it is mentioned that previous methods for multi-party dialogue response generation fine-tuned generative language models on small datasets with annotated addressee labels. However, this limits the availability of training data. The proposed method suggests focusing on the utilization of large unlabeled corpora instead. By leveraging the vast amount of unlabeled data, it is possible to pre-train response generation models for multi-party dialogues and improve their performance.\n\nOverall, the suggested methods of an Expectation-Maximization (EM) approach and utilizing large unlabeled corpora address the challenges of data scarcity and lack of annotated addressee labels in multi-party dialogue response generation. These approaches provide feasible solutions to improve the effectiveness and performance of response generation models for multi-party dialogues.'