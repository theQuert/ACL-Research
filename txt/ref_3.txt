Generally, methods for handling hallucinations can be either internal, i.e. using only information coming from the translation model itself, or external, i.e. using auxiliary models. In addition to these, we also consider “oracles” relying on reference translation. Note that these cannot be used in preventive settings when references are not available; here we use them only for analysis. Following previous work (Müller and Sennrich, 2021; Guerreiro et al., 2022), we use: • chrF: character n-gram F score of the translation with respect to the reference. We use the CHR F++ version that also takes into account word unigrams and bigrams (Popovi´c, 2017); • COMET: a neural quality estimation metric by Rei et al. (2020a) which was shown to be the state-of-the-art reference-based method (Kocmi et al., 2021). Baseline: Seq-Logprob. This is the standard length-normalized sequence log-probability. Compared to previously introduced methods specifically targeting hallucinations, this simple metric performs the best (Guerreiro et al., 2022). We use ALTI: percentage of source contribution. We compute the percentage of source impact on the generated translation using the recently introduced ALTI+ (Ferrando et al., 2022). At a high level, it decomposes each transformer block into a sum of functions of individual tokens and views an output representation as a summation of transformed input vectors. Then it evaluates contribution of these vectors to the resulting sum. Among other things, ALTI+ (as well as an earlier Layerwise Relevance Propagation (LRP) -based method by Voita et al. (2021)) was used to show that for artificially created hallucinations, source influence is much lower than for “healthy” translations. Our work is the first to test this intuition in a real setting where hallucinations are generated naturally.3  Formally, for a model and its generated translation, we compute the total source contribution as the sum of contributions of all source tokens. We do it for each target token individually and then average across target tokens. The scores are computed by the same model that produced the translations (Section 2.1). Baseline: COMET-QE. For a reference-free model, we use the state-of-the-art COMETQE (Rei et al., 2020b) for its superior performance compared to other quality estimators (Mathur et al., 2020; Freitag et al., 2021; Kocmi et al., 2021). We use: sentence similarity. Overall, we consider three measures based on pretrained models that evaluate semantic similarity of two sentences: • LASER: cosine similarity of source and translation sentence embeddings from LASER2. LASER2 (Heffernan et al., 2022) improves LASER (Artetxe and Schwenk, 2019) by replacing LSTM encoder with a Transformer and using teacher-student training; • LaBSE: cosine similarity of source and translation sentence embeddings from LaBSE (Feng et al., 2022). LaBSE is a dual-encoder approach based on pretrained transformers and fine-tuned for translation ranking with an additive margin softmax loss; • XNLI: product of the entailment probabilities of source to translation and translation to source. We compute entailment scores with RoBERTa (Conneau et al., 2020) finetuned on a combination of NLI data in 15 languages (Conneau et al., 2018).