We conduct experiments on three representative modeling approaches that have been used for simultaneous machine translation. Offline MT: a Transformer NMT model (Vaswani et al., 2017) trained on full sentences. Multipath Wait-k: a wait-k policy model (Elbayad et al., 2020) trained by randomly sampling different k values between batches during training. ITST: an adaptive read/write policy model (Zhang and Feng, 2022) that formulates the translation process as an optimal information transport problem. To the best of our knowledge, ITST is currently the state of the art method for SiMT. 5.2 Data We select three datasets of different language pairs that have been used before for investigations of SiMT models. WMT15 De→En (Callison-Burch et al., 2009) is a parallel corpus with 4.5M training pairs, which are tokenized and split using 32K BPE merge operations with a shared vocabulary for German and English. We use newstest2013 (3000 sentence pairs) as the development set and report results on newstest2015 (2169 sentence pairs). CWMT19 2 Zh→En contains 9.4M sentence pairs in the training set, which are tokenized and split using 32K BPE merge operations for both the source and the target languages. We use the validation set of 956 sentence pairs from BSTC (Zhang et al., 2021a) as the test set. IWSLT15 En→Vi (Luong and Manning, 2015) contains 133K training pairs. We use TED tst2012 as the validation set (1553 sentence pairs) and TED tst2013 as the test set (1268 sentence pairs). Following the settings in (Ma et al., 2020), we replace rare tokens (frequency < 5) by <unk>. The resulting vocabulary sizes are 17K and 7.7K for English and Vietnamese respectively. Figure 3 compares AR curves at various k values in both the original and the reconstructed training data with pseudo-targets. Our two KD methods can effectively reduce the anticipation rate across all language pairs at different k values, with monotonic KD typically resulting in a lower anticipation rate compared to the standard KD. Our experiments are focused on understanding the impact of changes on the translation quality of SiMT models. To properly evaluate SiMT performance, the test sets should be representative of the characteristics of real-time simultaneous translation, in both content and translation style. In addition to the official test sets described earlier, we choose to adapt the WMT newstest2015 De→En data set for realtime speech translation. We select 500 sentence pairs from this data set and ask professional translators to produce new reference translations, with as much monotonicity as linguistically possible without compromising the translation quality. The detail of this annotation task can be found in the Appendix D. We use Transformer-base models for the De→En and Zh→En translation directions and Transformersmall mdoels for En→Vi. Our model configurations generally follow the experiment settings detailed in Multipath Wait-k 3 and ITST 4 . For generating pseudo-targets, we use a beam size of 5 in standard KD, and in our two-stage monotonic KD method we set beam sizes b 1 = 10 and b 2 = 5, with the latency value k set to 7, 7, 6 for De-En, Zh-En, and En-Vi respectively. For evaluation, we use tokenized case-insensitive BLEU 5 for translation quality and Average Lagging (AL, token level) (Ma et al., 2019a) to measure latency. We first train an offline MT model for each of the three language pairs on the original training data, and then obtain pseudo parallel data and train Multipath Wait-k and ITST models using the regular and monotonic KD methods described in Section 4. Offline MT Evaluation For each language pair, we train two additional offline models, one for each of the two KD methods. We evaluate these models in both offline and simultaneous scenarios, adopting a simple wait-k policy for the latter. The results 6 are presented in Figure 4. The offline mod-els perform significantly worse in the streaming scenario, especially when at a low latency, due to the discrepancy between full-sentence training and prefix-to-prefix inference. The two models trained on pseudo-target data exhibit considerable improvements, with an average improvement of more than 2 BLEU points across all latency settings on the De→En test set in particular. We attribute this improvement to the more monotonic nature of the pseudo data generated through KD. Models trained with this data can better model local source-target relationships, which leads to higher quality translations on partial source inputs. This is reflected in Figure 5, where the mass of cross-attention weights concentrate around the diagonal. Multipath Wait-k We train wait-k SiMT models, following (Elbayad et al., 2020), on the original training data as well as the reconstructed training data with pseudo-target produced by the two KD methods. As shown in Figure 6, two KD methods are both able to significantly improve translation quality across latency settings. ITST Finally we train ITST models, following Zhang and Feng (2022), to see if our methods can achieve similar improvements with advanced adaptive read/write models. The results are shown in Figure 7. Similarly, we observe overall improvement in translation quality by training ITST models on the pseudo data. As illustrated in the example in Figure 9, the decoding path of the mono-KD trained ITST model is closer to the diagonal and its translation is more faithful and monotonic to the source input.