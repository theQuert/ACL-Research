In this section, we propose a two-stage framework to tackle the problem of self-adaptive ICL. In such a combinatorial optimization problem, an exhaustive search is not tractable. So we need specialized algorithms that can quickly rule out large parts of the search space. We present an overview of our selection-then-rank framework here: We ﬁrst use a selection module to reduce the search space. One straightforward choice for pre-ranking would be to use nearest-neighbor algorithms to select examples that are semantically similar to test samples. The results are then fed into the ranking module, which picks the best combination and permutation according to information-theoretic-driven criteria. The goal of selection module is to ﬁlter out large parts of “less useful” examples and construct a small candidate set to reduce the search space. We present various selection methods below. TopK Liu et al. (2022) and Gao et al. (2021) observe that context examples that are closer to the test sample in the embedding space consistently give rise to stronger performance. This observation leads to the TopK method which uses the nearest neighbors of a given test sample as the corresponding in-context examples. VoteK Although ICL was originally proposed for few-shot settings, they often require a large example set to achieve good performance. VoteK (Su et al., 2022) proposes to alleviate this problem by selecting diverse yet representative examples. Intuitively, VoteK is built upon TopK, but it increases diversity by penalizing examples similar to those already selected. DPP Inspired by VoteK, we also experimented with the determinantal point process (DPP) based method, which is proposed for set selection problems where diversity is preferred. We refer readers to Kulesza and Taskar (2011) for details of DPP. With the candidates returned by the selection module, the goal of the ranking module is to determine the best organization among candidates. Our ranking algorithm is inspired by the compression viewpoint of Solomonoff’s general theory of inference (Solomonoff, 1964) and Minimum Description Length (MDL) principle (Grünwald, 2007) from information theory. Both Solomonoff’s theory and the MDL formalize Occam’s razor and hold that a good model of data is a model that is good at losslessly compressing the data, including the cost of describing the model itself. These theories have led to advances in VAE (Kingma and Welling, 2013), and information bottleneck methods (Tishby and Zaslavsky, 2015). Inspired by the compression viewpoint of learning, we recast the problem of self-adaptive in-context learning into a similar paradigm. We assume that a good organization of in-context examples is the organization that is good at losslessly compressingtesting samples. This allows us to give a clear optimization objective when searching for the best organization c ∗ : c ∗ = arg min L θ (y | c, x) + L(θ), (2) c ∈ C where each c represents one possible organization of examples. L θ (y | c, x) is the codelength required to compress and transmit testing label y given the organization c and testing input x. L(θ) is the codelength required to describe the model, which can be ignored during ranking since all organizations use the same model without parameter updating. The codelength required for data transmission can be calculated using Shannon-Huffman code: (3) L θ (y | c, x) = −log 2 p(y | c, x). However, since we don’t have access to testing label y when ranking, the exact computation of p(y | c, x) is impossible. To tackle this problem, we propose to compute the expectation of codelength as the surrogate: L θ (y | c, x) ≈ −E q(y i | Y ) log 2 p(y i | c, x), (4) where q(y i | Y ) is the prior of y i among all possible labels Y . A natural design choice of the prior is a uniform distribution, given that most datasets are label-balanced. However, since we focus on instance-level selection rather than corpus level, the likelihood p(y i | Y ) can vary signiﬁcantly given different samples. We thus model this term using p(y i | c, x), leading to our ﬁnal objective: Connection to entropy When we use model conﬁdence p(y i | c, x) as the estimation of q(y i | Y ), Eq 4 is basically calculating the entropy. Minimizing entropy is equivalent to searching for in-context examples that will lead to a skewed probability distribution. In other words, we are searching for in-context examples are will make PLMs very conﬁdent about its answer. This motivation is exactly opposite to the Local Entropy(LocalE) metric proposed by Lu et al. (2022), where they search by maximizing the entropy. Connection to cross-entropy. Note that in this paper, we focus on instance level ICL and assume no validation set is available. However, when we have a validation set to directly compute p(y | c, x), Eq 3 is exactly the categorical cross-entropy loss. Hence, trying to minimize the description length of the outputs is equivalent to minimizing the usual classiﬁcation loss. This reveals why compression is another viewpoint of learning. Connection to mutual information. Previous effort (Blier and Ollivier, 2018) has proved that the compression is limited by the mutual information between inputs and outputs: H(y)−E q [L(y | x)] ≤ H(y)−H(y | x) = I(y; x), where we assume the inputs and outputs follow the joint distribution q. Based on this ﬁnding, any successful compression of the labels is, at the same time, a direcestimation of the mutual information between input and output. This connects our method to Sorensen et al. (2022) that selects tem-c ∗ = arg min −E p(y i | c,x) log 2 p(y i | c, x). (5) plates by maximizing mutual information. c ∈ C Now that we have an interpretable metric for ranking, we can brute-force all possible permutations to obtain the optimal ranking result. Although we have signiﬁcantly reduced the search space using the selection module, enumerating all organizations is still infeasible. For instance, if we want to search for the best organization that contains 8 examples, even a small candidate set of 10 examples can result in 1.8 million choices (A 10 8 ). At the current stage, we randomly sample 10 permutations for ranking. We leave it as an interesting future work to investigate how to approximate the optimal ranking better. 4.4 Interpretation of L θ (y | c, x) Except for the compression viewpoint, we offer some other interpretations of our method here. Connection to entropy When we use model conﬁdence p(y i | c, x) as the estimation of q(y i | Y ), Eq 4 is basically calculating the entropy. Minimizing entropy is equivalent to searching for in-context examples that will lead to a skewed probability distribution. In other words, we are searching for in-context examples are will make PLMs very conﬁdent about its answer. This motivation is exactly opposite to the Local Entropy(LocalE) metric proposed by Lu et al. (2022), where they search by maximizing the entropy. Connection to cross-entropy. Note that in this paper, we focus on instance level ICL and assume no validation set is available. However, when we have a validation set to directly compute p(y | c, x), Eq 3 is exactly the categorical cross-entropy loss. Hence, trying to minimize the description length of the outputs is equivalent to minimizing the usual classiﬁcation loss. This reveals why compression is another viewpoint of learning. Connection to mutual information. Previous effort (Blier and Ollivier, 2018) has proved that the compression is limited by the mutual information between inputs and outputs: where we assume the inputs and outputs follow the joint distribution q. Based on this ﬁnding, any successful compression of the labels is, at the same time, a direct estimation of the mutual information between input and output. This connects our method to Sorensen et al. (2022) that selects tem-plates by maximizing mutual information. Difference to previous works. Except for the aforementioned connections and differences, our method signiﬁcantly differs from Lu et al. (2022) and Sorensen et al. (2022) in that we perform instance-level selection without a validation set. Trivial extension of previous methods to our setting is impractical: Lu et al. (2022) requires a validation set to compute the Global Entropy, while the mutual information is always zero on instance-level setting according to Sorensen et al. (2022).