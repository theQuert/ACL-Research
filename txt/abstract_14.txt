Existing neural models have difficulty generalizing to unseen combinations of seen components. To achieve compositional generalization, models are required to consistently interpret (sub)expressions across contexts. Without modifying model architectures, we improve the capability of Transformer on compositional generalization through consistency regularization training, which promotes representation consistency across samples and prediction consistency for a single sample. Experimental results on semantic parsing and machine translation benchmarks empirically demonstrate the effectiveness and generality of our method. In addition, we find that the prediction consistency scores on in-distribution validation sets can be an alternative for evaluating models during training, when commonly-used metrics are not informative. Compositional (systematic) generalization refers to the ability to understand and produce a potentially infinite number of novel combinations of known atoms (Chomsky, 2009; Janssen and Partee, 1997). Achieving compositional generalization requires a model to perform consistently in the interpretation assigned to a (sub)expression across contexts (Janssen and Partee, 1997; Dankers et al., 2022). Recently, the Transformer architecture has become the standard for natural language processing (NLP), particularly in supporting large pretrained language models (PLMs) such as T5 and GPT-3 (Raffel et al., 2020; Brown et al., 2020). We observe that limitation of compositional generalization in Transformer can arise from the internal inconsistency under the standard training paradigm. Without modifying model architectures, we improve compositionality of Transformer with consistency regularization training in terms of representation and prediction. 