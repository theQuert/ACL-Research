In this section, the overall architecture of our proposed model Dual-Span is shown in Figure 2, which consists of four main components: sentence encoding, feature enhancing module, dual-channel span generation and triplet module. For a sentence X = { w 1 , w 2 , . . . , w n } of length n, the ASTE task is to extract the set of aspect sentiment triplets T = { (a, o, s) m } m=1 | T | from the given sentence X, where a, o and s ∈ { POS, NEU, NEG } represent the aspect term, opinion term and sentiment polarity, respectively. | T | is the number of sentiment triplets contained sentence X. To obtain contextual representations for each word, we explore two sentence encoding methods, namely, BiLSTM and BERT. BiLSTM We first use the GloVe (Pennington et al., 2014) embedding to get the embedding matrix E ∈ R V | | ∗d w of the corpus, where | V | represents the vocabulary size, and d s represents the embedding dimension. For the embedding tokens E x = { e 1 , e 2 , . . . , e n } in the sentence, we use BiLSTM to get its hidden representation H = { h 1 , h 2 , . . . , h n } , where h ∈ R 2d n is obtained by → splicing the hidden state h ∈ R d n generated by forward LSTM and the hidden state h ∈ R d n generated by backward LSTM: → ← h = [ h ; h ] (1) BERT An alternative approach is to utilize BERT (Devlin et al., 2019) as the sentence encoder to generate contextualized word representations. Given a sentence X = { w 1 , w 2 , . . . , w n } with n words, the hidden representation sequence H = { h 1 , h 2 , . . . , h n } is the output of the encoding layer of BERT at the last transformer block. As aforementioned, spans (or intra-span words) involve syntactical dependency and part-of-speech correlation, therefore incorporating those information into feature representations can be beneficial for span pairing and sentiment prediction. To capture the high order dependency relations, here we devise a graph neural network based method to encode the syntactic dependency and part-of-speech relations of intra- and inter-spans in high orders. In particular, we construct the part-of-speech relational graph (corresponding to a multi-relation matrix as shown in Figure 3 (b)). Then we apply two relational graph attention networks to learn the high order interactions between words on syntactic dependency tree of the sentence in question and constructed part-of-speech graph, respectively. The goal of part-of-speech graph construction is to characterize the word formation patterns of aspect and opinion terms so as to better identify the possible spans. Specifically, we adopt the following three rules to construct the part-of-speech graph G Pos = (V, R Pos ) of a given sentence X. First, following previous work (Chakraborty et al., 2022), assuming that aspect terms are usually nouns and opinion terms are usually adjectives, we can define part-of-speech relations based on part-of-speech tags NN or JJ. In particular, we consider the relations between words in a given window that contains words tagged with NN or JJ. Therefore, a relational edge R i,j Pos of G Pos is defined for two words i and j as the combination of part-of-speech tags of the two words, whose representation vector is r i,j p ∈ R d p , where d p is the dimension of part-of-speech combination embedding. Besides, we consider the special syntactic relation nsubj, since opinion terms are usually directly used to modify aspect terms, leading to better extraction of aspect-opinion pairs. Finally, for each word’s part-of-speech, we add a self-loop relational edge to itself, as the diagonal elements shown in Figure 3.  On the other hand, the syntactic dependency graph G Syn = (V, R Syn ) is constructed according to the dependency parsing tree, where edges are represented by syntactic relation types. Moreover, we define the self-dependency for each word. So for a given sentence of length n, the syntactic relation between words w i and w j is denoted as R i,j Syn , whose corresponding vectorization representation is denoted as the vector r i,j s ∈ R d s , where d s is the dimension of syntactic relation embeddings. Next, we use relational graph attention networks (RGAT) to capture the multiple types of linguistic features and high-order interaction between spans/words on syntactic dependency graph and part-of-speech graph, respectively. Moreover, we use two graph attentional network based modules, namely, SynGAT and PosGAT to learn syntactic dependency graphs and part-of-speech graphs, respectively, which will distinguish between various syntactic relationships and part-of-speech relationships when calculating the attention weight between nodes. In particular, following previous work (Bai et al., 2021), we denote two specific relations on each edge by r i,j s and r i,j p , respectively. Specifically, for the i−th node, the update process is as follows: where W s2 l ∈ R z ×d and W p2 l ∈ R z ×d are parameter matrices. z denotes the number of attention heads, and σ is the sigmoid activation. N i is the set ˆ of immediate neighbors of node i. α i,j (lz) ˆ , β i,j (lz) are the normalized attention coefficients for the z-th head at the l-th layer. To fuse syntactic dependency and part-of-speech relation features, we introduce a gating mechanism (Cho et al., 2014) to merge the two views as follows: where ◦ is element-wise product operation. [h syn : h pos ] is the concatenation of h syn and h pos , and W g and b g are model parameters. This way, g is learned to optimize the feature fusion. In this section, we propose a dual-channel span generation module, which consists of two parts: dual-channel span generation and span classification. Syntactic Span Generation Given a sentence X whose syntactic dependency graph is G Syn = (V, R Syn ), if there is a dependency edge e ij between words w i and w j , then all words positioned between them are considered to be a span s i,j syn . In particular, self-dependent edges represents spans of length L s = 1. We define the representation of s i,j syn as follows where f width (i, j) denotes trainable embedding of span length (i.e., j − i + 1 ). e i,j = 1 suggests that there is an edge between w i and w j . Part-of-speech Span Generation For a given sentence X = { w 1 , w 2 , . . . , w n } , if the part-of-speech tag of word w o is NN or JJ, the words in a predefined window will be exhaustively enumerated and then the enumeration is further combined with central word w o to form spans. The part-of-speech induced span s k,l pos can be represented as: where f width (k, l) refers to the trainable embedding of span length. Finally, we merge the two types of span candidates: S = s i,j syn ∪ s k,l pos . Compared to exhaustive enumeration on the whole sentence in previous span-based approaches, whose time complexity of enumerated spans is O(n 2 ), for a sentence of length n. However, in our syntactic span generation, the parsing tree containing 2n edge dependencies (Qi et al., 2020) (including self-dependent edges), so the number of generated spans is O(2n). On the other hand, the statistics shows that in the benchmark datasets, there are about 2.5 part-of-speech NN and JJ in each sentence on average. Therefore, in the part-of-speech span generation procedure, the number of span candidates is O(2.5S (S window − 1)) ≤ n, where S window is thewindow window size to restrict span length and generally set to be a small value (e.g., S window = 3 in our experiments). That is, the time complexity of our method to generate the span is O(n), which significantly reduce the span candidate size. After obtaining the span candidates S, we further narrow down the pool of possible spans by leveraging two auxiliary tasks, namely, ATE and OTE tasks. Specifically, all span candidates in S will be classified into one of the three categories: { Aspect, Opinion, Invalid } by a span classifier. Next, nz spans are singled out with higher prediction scores Φ aspect or Φ opinion , where z is the threshold hyper-parameter and Φ aspect and Φ opinion are obtained by where FFNN denotes a feed-forward neural network with non-linear activation. Based on the shrinked candidate pool of aspect and opinion terms, the aspect candidate s a,b a ∈ Sa  and opinion candidate s c,d o ∈ S o are paired and represented as g s a,b a ,s c,d o = [ s a,b a : s c,d o : r ab,cd s : f distance (a, b, c, d) ] . (10) where f distance (a, b, c, d) denotes trainable embeddings of span length. r ab,cd s is a trainable embedding vector which is the average pooling of the dependency vectors between words ab and cd. Additionally, since opinions are more likely to modify the aspects that match them, we consider the dependency relationship r ab,cd s ∈ R Syn between them. Then, sentiment classification is performed for the obtained span pairs, where the sentiment types are defined as r ∈ R = { Positive, Negative, Neutral, Invalid } Formally, the triplet prediction is written as s a,b a , s c,d o ) = softmax FFNN r gs a,b a ,s c,d o  ( ( )) (11) The loss function for training is defined as the sum of the negative log-likelihoods from the span-pair classification in the span-classification and triplets modules: L = − ∑ log P ( t i,j | s i,j ) s i,j ∈ S (12) − s a,b t ∈ S ∑ log P ( rˆ | s a,b a , s c,d o ) a ,s c,d o ∈ So  where t i,j and ri,j ˆ are the ground truth labels for span s i,j and span-pair (s a,b a , s c,d o ), respectively. S, S a and S o are the final span representation, pruned aspect and opinion candidate pools in dual-channel span generation, respectively.