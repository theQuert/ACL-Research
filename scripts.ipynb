{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33cd0b79-759a-4dfa-ac14-df415b4819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d0a7323-c914-4596-b533-ef1805083508",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'bibtexparser' has no attribute 'load'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./anthology+abstracts.bib\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m bibtex_file:\n\u001b[0;32m----> 2\u001b[0m     bib_database \u001b[38;5;241m=\u001b[39m \u001b[43mbibtexparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m(bibtex_file)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Extracting entries\u001b[39;00m\n\u001b[1;32m      6\u001b[0m entries \u001b[38;5;241m=\u001b[39m bib_database\u001b[38;5;241m.\u001b[39mentries\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'bibtexparser' has no attribute 'load'"
     ]
    }
   ],
   "source": [
    "with open('./anthology+abstracts.bib', 'r') as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)\n",
    "\n",
    "# Extracting entries\n",
    "\n",
    "entries = bib_database.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f88822-0225-4348-a152-9c77ad9638cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibtex_str = \"\"\"\n",
    "@comment{\n",
    "    This is my example comment.\n",
    "}\n",
    "\n",
    "@ARTICLE{Cesar2013,\n",
    "  author = {Jean César},\n",
    "  title = {An amazing title},\n",
    "  year = {2013},\n",
    "  volume = {12},\n",
    "  pages = {12--23},\n",
    "  journal = {Nice Journal}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9e7fb-16d1-4e15-89e3-a737f483b629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "file_path = os.path.join(\"./\", \"anthology+abstracts.bib\")\n",
    "library = bibtexparser.parse_file(file_path)\n",
    "entries = library.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b259e972-2757-4737-939b-1e6f08f98b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry(entry_type=`inproceedings`, key=`krishna-etal-2023-neural`, fields=`[Field(key=`title`, value=`Neural Approaches for Data Driven Dependency Parsing in {S}anskrit`, start_line=11), Field(key=`author`, value=`Krishna, Amrith  and\n",
       "      Gupta, Ashim  and\n",
       "      Garasangi, Deepak  and\n",
       "      Sandhan, Jeevnesh  and\n",
       "      Satuluri, Pavankumar  and\n",
       "      Goyal, Pawan`, start_line=12), Field(key=`booktitle`, value=`Proceedings of the Computational {S}anskrit {\\&} Digital Humanities: Selected papers presented at the 18th World {S}anskrit Conference`, start_line=18), Field(key=`month`, value=`jan`, start_line=19), Field(key=`year`, value=`2023`, start_line=20), Field(key=`address`, value=`Canberra, Australia (Online mode)`, start_line=21), Field(key=`publisher`, value=`Association for Computational Linguistics`, start_line=22), Field(key=`url`, value=`https://aclanthology.org/2023.wsc-csdh.1`, start_line=23), Field(key=`pages`, value=`1--20`, start_line=24)]`, start_line=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[1]\n",
    "# 2023.wsc-csdh.1/\n",
    "# https://aclanthology.org/2023.wsc-csdh.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c84dd2a6-673d-4ef0-bb69-840e242003ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://aclanthology.org/2023.wsc-csdh.5'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = str(entries[5]).split(\"`url` = \")[-1].split(\"`\")\n",
    "[ele for ele in lst if ele][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245f670-35ca-480a-83a4-e6618f4afd39",
   "metadata": {},
   "source": [
    "### Test PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "971766cc-ebdd-4957-ae50-14aab6fcbd01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1322 Related Work',\n",
       " 'Question generation frequently refers to the task',\n",
       " 'of generating a natural language questions based',\n",
       " 'on a text (Zhang et al., 2021). The generation can',\n",
       " 'be conditioned on the manually spotted expected',\n",
       " 'answer in the text (Murakhovs’ka et al., 2022; La-',\n",
       " 'ban et al., 2022), whereas generating them in a free',\n",
       " 'way (Duan et al., 2017), even potentially generating',\n",
       " 'possible answers (Tafjord and Clark, 2021).',\n",
       " 'In the ﬁeld of knowledge-based approaches, sev-',\n",
       " 'eral propositions have been made for the verbaliza-',\n",
       " 'tion of formal queries (in SQL, SPARQL, OWL,',\n",
       " 'etc.) through rules or templates (Ngonga Ngomo',\n",
       " 'et al., 2013, 2019; Kusuma et al., 2020), or in-',\n",
       " 'termediate representations (Guo et al., 2019; Gan',\n",
       " 'et al., 2021), leading to verbalizations with a vari-',\n",
       " 'able naturalness. Using neural approaches, several',\n",
       " 'contributions have been made to generate ques-',\n",
       " 'tions from RDF triples (Han et al., 2022) or small',\n",
       " 'KGs depicting multi-hop questions (Serban et al.,',\n",
       " '2016; Kumar et al., 2019). In (Bi et al., 2020),',\n",
       " 'this principle is improved by enriching the entities',\n",
       " 'from the triples with information from a broader',\n",
       " 'KG. A limit of these approaches is that they cannot',\n",
       " 'cover several features offered by query language',\n",
       " 'like SPARQL (e.g., union of triples, ﬁlters, aggre-',\n",
       " 'gation functions, etc.). Hence, to the best of our',\n",
       " 'knowledge, our work is the ﬁrst attempt to study',\n",
       " 'the verbalization of SPARQL seeking to generate a',\n",
       " 'large diversity of questions types.',\n",
       " 'Among other related work, Knowledge-Based',\n",
       " 'QA (KBQA) tasks are interesting to study since',\n",
       " 'they provide data with paired natural language',\n",
       " 'question and formal representation (usually triples',\n",
       " 'or SPARQL queries) (Bordes et al., 2015; Dubey',\n",
       " 'et al., 2019; Kacupaj et al., 2020; Biswas et al.,',\n",
       " '2021; Kacupaj et al., 2021; Cui et al., 2022). It',\n",
       " 'is important to note that some of these corpora',\n",
       " 'overlap because they are extensions or reﬁnements',\n",
       " 'of common ancestors. Less datasets exist when',\n",
       " 'considering the conversational KBQA: ConvQues-',\n",
       " 'tions (Christmann et al., 2019) and CSQA (Saha',\n",
       " 'et al., 2018). While the former does not provide',\n",
       " 'the formal representations associated to the nat-',\n",
       " 'ural language questions, the latter is relevant for',\n",
       " 'our task. Finally, in the ﬁeld of dialogue, propo-',\n",
       " 'sitions have also raised to enable interoperability',\n",
       " 'with KGs through a formal language (Lam et al.,',\n",
       " '2022). However, annotated datasets are usually pri-',\n",
       " 'vate or small. Hence, the conversational dimension',\n",
       " 'in our SPARQL-to-text task is original.3 Datasets',\n",
       " 'In this paper, 4 KBQA corpora from the literature',\n",
       " 'are used: SimpleQuestions (Bordes et al., 2015),',\n",
       " 'LC-QuAD 2.0 (Dubey et al., 2019), ParaQA (Kacu-',\n",
       " 'paj et al., 2021), and CSQA (Saha et al., 2018).',\n",
       " 'They have different characteristics, and they do not',\n",
       " 'overlap. Additionnaly, a new corpus is introduced',\n",
       " 'to serve as a challenge set, i.e. no training data is',\n",
       " 'available for it. This corpus has been generated',\n",
       " 'based on the WebNLG v.3.0 corpus (Ferreira et al.,',\n",
       " '2020), and is referred to as WebNLG-QA. This sec-',\n",
       " 'tion presents an overview of the 4 corpora from the',\n",
       " 'literature, the generation process and resulting con-',\n",
       " 'tent of WebNLG-QA, and how all these datasets',\n",
       " 'were homogenized. General statistics and exam-',\n",
       " 'ples for the 5 resulting SPARQL-to-text datasets',\n",
       " 'are given in Table 1 and 2.',\n",
       " '3.1 Existing corpora',\n",
       " 'SimpleQuestions originally does not include',\n",
       " 'SPARQL queries but (subject, property, object)',\n",
       " 'triples. Each triple is paired with a question whose',\n",
       " 'expected answer is either the object or the subject',\n",
       " 'of the triple. Hence, all questions are asking for',\n",
       " 'an entity (\"what is...\", \"which...\", \"who...\"). The',\n",
       " 'triples’ elements were initially taken from Free-',\n",
       " 'Base, but were ported to WikiData2.',\n",
       " 'LC-QuAD 2.0 and ParaQA directly include',\n",
       " 'SPARQL queries for both DBPedia (WikiData as',\n",
       " 'well in LC-QuAD 2.0). Questions are more varied',\n",
       " 'than in SimpleQuestions. Expected answers can be',\n",
       " 'entities, numbers or booleans. Some question are',\n",
       " 'even unanswerable in LC-QuAD 2.03. Questions',\n",
       " 'in LC-QuaD 2.0 are sometimes of poor quality as',\n",
       " 'they were semi-automatically generated, whereas',\n",
       " 'ParaQA’s questions are more natural but the dataset',\n",
       " 'is much smaller.',\n",
       " 'CSQA is a very large corpus of conversational',\n",
       " 'question-answering based on Wikidata. Queries are',\n",
       " 'given in a custom formalism instead of SPARQL.',\n",
       " 'The questions include coreferences and ellipses,',\n",
       " 'potentially with clariﬁcation steps when they are',\n",
       " 'ambiguous. CSQA covers a wide range of ques-',\n",
       " 'tions types such as (single or multiple triples, en-',\n",
       " 'tity/numeric/boolean answers, comparative ques-',\n",
       " 'tions, etc.). Nonetheless, the linguistic diversity of',\n",
       " 'the questions is low and some are unnatural.',\n",
       " '2https://github.com/askplatypus/',\n",
       " 'wikidata-simplequestions',\n",
       " '3This means that no answer can be found in the KG, not',\n",
       " 'that the question does make sense. Hence, this should not',\n",
       " 'bother the SPARQL-to-text models.']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PyPDF2 import PdfReader, PdfReader\n",
    "\n",
    "# open the PDF file\n",
    "reader = PdfReader('/Users/quert/Downloads/2022.aacl-main.11.pdf', 'rb')\n",
    "\n",
    "page = reader.pages[1]\n",
    "extracted_text = page.extract_text()\n",
    "splitted = extracted_text.split(\"\\n\")\n",
    "splitted\n",
    "# find the indices of \"Abstract\" and \"1 Introduction\"\n",
    "# splitted.index(\"Abstract\")\n",
    "# print(extracted_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl-venv",
   "language": "python",
   "name": "acl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
