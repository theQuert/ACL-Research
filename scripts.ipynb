{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "33cd0b79-759a-4dfa-ac14-df415b4819d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import bibtexparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0a7323-c914-4596-b533-ef1805083508",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./anthology+abstracts.bib', 'r') as bibtex_file:\n",
    "    bib_database = bibtexparser.load(bibtex_file)\n",
    "\n",
    "# Extracting entries\n",
    "\n",
    "entries = bib_database.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4f88822-0225-4348-a152-9c77ad9638cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bibtex_str = \"\"\"\n",
    "@comment{\n",
    "    This is my example comment.\n",
    "}\n",
    "\n",
    "@ARTICLE{Cesar2013,\n",
    "  author = {Jean CÃ©sar},\n",
    "  title = {An amazing title},\n",
    "  year = {2013},\n",
    "  volume = {12},\n",
    "  pages = {12--23},\n",
    "  journal = {Nice Journal}\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a9e7fb-16d1-4e15-89e3-a737f483b629",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import bibtexparser\n",
    "file_path = os.path.join(\"./\", \"anthology+abstracts.bib\")\n",
    "library = bibtexparser.parse_file(file_path)\n",
    "entries = library.entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b259e972-2757-4737-939b-1e6f08f98b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Entry(entry_type=`inproceedings`, key=`krishna-etal-2023-neural`, fields=`[Field(key=`title`, value=`Neural Approaches for Data Driven Dependency Parsing in {S}anskrit`, start_line=11), Field(key=`author`, value=`Krishna, Amrith  and\n",
       "      Gupta, Ashim  and\n",
       "      Garasangi, Deepak  and\n",
       "      Sandhan, Jeevnesh  and\n",
       "      Satuluri, Pavankumar  and\n",
       "      Goyal, Pawan`, start_line=12), Field(key=`booktitle`, value=`Proceedings of the Computational {S}anskrit {\\&} Digital Humanities: Selected papers presented at the 18th World {S}anskrit Conference`, start_line=18), Field(key=`month`, value=`jan`, start_line=19), Field(key=`year`, value=`2023`, start_line=20), Field(key=`address`, value=`Canberra, Australia (Online mode)`, start_line=21), Field(key=`publisher`, value=`Association for Computational Linguistics`, start_line=22), Field(key=`url`, value=`https://aclanthology.org/2023.wsc-csdh.1`, start_line=23), Field(key=`pages`, value=`1--20`, start_line=24)]`, start_line=10)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entries[1]\n",
    "# 2023.wsc-csdh.1/\n",
    "# https://aclanthology.org/2023.wsc-csdh.1/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c84dd2a6-673d-4ef0-bb69-840e242003ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://aclanthology.org/2023.wsc-csdh.5'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lst = str(entries[5]).split(\"`url` = \")[-1].split(\"`\")\n",
    "[ele for ele in lst if ele][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0245f670-35ca-480a-83a4-e6618f4afd39",
   "metadata": {},
   "source": [
    "### PDF to text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "971766cc-ebdd-4957-ae50-14aab6fcbd01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "\n",
    "# open the PDF file\n",
    "reader = PdfReader('/Users/quert/Documents/GitHub/acl-research/papers/2023.acl-long.2.pdf', 'rb')\n",
    "\n",
    "texts = []\n",
    "for idx in range(len(reader.pages)):\n",
    "    page = reader.pages[idx]\n",
    "    extracted = page.extract_text().split(\"\\n\")\n",
    "    texts.extend(extracted)\n",
    "    \n",
    "# find the idx of \"Related Work\", \"Datsets\"\n",
    "id_related_work = []\n",
    "for idx in range(len(texts)):\n",
    "    list_ele = None\n",
    "    try:\n",
    "        if ['Related', 'Work'] == texts[idx].split()[-2:]:\n",
    "            id_related_work.append(idx)\n",
    "    except: pass\n",
    "# find the idx of \"Abstract\"\n",
    "\n",
    "id_abstract = []\n",
    "for idx in range(len(texts)):\n",
    "    try:\n",
    "        if ['Abstract'] == texts[idx].split()[-2:]:\n",
    "            id_abstract.append(idx)\n",
    "    except: pass\n",
    "\n",
    "# find the idx of \"Introduction\"\n",
    "\n",
    "id_intro = []\n",
    "for idx in range(len(texts)):\n",
    "    try:\n",
    "        if ['Introduction'] == texts[idx].split()[-1:]:\n",
    "            id_intro.append(idx)\n",
    "    except: pass\n",
    "\n",
    "# find the idx of \"Conclusion\"\n",
    "\n",
    "id_conclusion = []\n",
    "for idx in range(len(texts)):\n",
    "    try:\n",
    "        if ['Conclusion'] == texts[idx].split()[-1:] or \"Conclusion\" in texts[idx].split()[-4:]:\n",
    "            id_conclusion.append(idx)\n",
    "    except: pass\n",
    "\n",
    "# find the idx of \"Reference\"\n",
    "id_reference = []\n",
    "for idx in range(len(texts)):\n",
    "    try:\n",
    "        if ['Reference'] == texts[idx].split()[-1]:\n",
    "            id_reference.append(idx)\n",
    "    except: pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "6acc10c9-3ab6-4a7c-949d-ce4c2aa6e39e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([9], [43], [165], [754], [])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id_abstract, id_intro, id_related_work, id_conclusion, id_reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e933dc28-d506-4b99-88a6-8bc213715918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the top-N articles from \"Related Work\"\n",
    "from refextract import extract_references_from_file\n",
    "references = extract_references_from_file('/Users/quert/Documents/GitHub/acl-research/papers/2023.acl-long.2.pdf')\n",
    "print(references[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0330c4c3-24e9-42b5-aca3-0a97954e0426",
   "metadata": {},
   "source": [
    "### Scrape texts from ACL site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "ff10a834-c0a3-4c31-9253-bd5316ddbfb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "urls = [f\"https://aclanthology.org/2023.acl-long.{idx}\" for idx in range(1, 41)]\n",
    "\n",
    "abstract_texts = []\n",
    "error_ids = []\n",
    "\n",
    "\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/116.0.0.0 Safari/537.36\"}\n",
    "r = requests.get(url=url, params={'param':'1'}, headers={'Connection':'close'})\n",
    "\n",
    "\n",
    "\n",
    "for idx in range(len(urls)):\n",
    "    response = requests.get(url=urls[idx], params={'param':'1'}, headers={'Connection':'close'})\n",
    "    try:\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            abstract_tag = soup.find('div', {'class': 'acl-abstract'})\n",
    "            abstract_text = str(abstract_tag).split(\"<span>\")[1]\n",
    "            abstract_texts.append(abstract_text)\n",
    "    except:\n",
    "        error_ids.append(idx)\n",
    "abstract_texts = [abstract_texts[idx].rstrip(\"</span></div>\") for idx in range(len(abstract_texts))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed8d3a-aaeb-4b08-a58c-89a0e2a4a810",
   "metadata": {},
   "source": [
    "### Analyze data from ACL OCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c3f4151-a91a-4974-8149-29056b1431a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dataset = pd.read_csv(\"./ACT2_dataset.tsv\", sep=\"\\t\", index_col=\"unique_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "253d0ca0-39a1-4ebe-9c82-2c36dcab03f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['core_id', 'citation_offset', 'total_doc_length', 'section_info',\n",
       "       'citing_title', 'citing_author', 'citing_publication_info',\n",
       "       'citing_abstract', 'cited_title', 'cited_author', 'cited_abstract',\n",
       "       'cited_doi', 'cited_publication_date', 'cited_publication_info',\n",
       "       'citation_context', 'self_citation', 'direct_citations', 'co_mentions',\n",
       "       'citation_class_label', 'citation_influence_label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns\n",
    "\n",
    "# citing abstract with id=7\n",
    "# cited abstract with id=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77fea368-52a4-4ce4-8e80-e917298fb55f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032, 3032)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cited_abstracts = dataset[\"cited_abstract\"].to_list()\n",
    "citing_abstracts = dataset[\"citing_abstract\"].to_list()\n",
    "\n",
    "cleaned_cited_abstracts, cleaned_citing_abstracts, cleaned_id = [], [], []\n",
    "for i in range(4000):\n",
    "    if str(cited_abstracts[i]) != \"nan\" and str(citing_abstracts[i]) != \"nan\":\n",
    "        cleaned_cited_abstracts.append(cited_abstracts[i])\n",
    "        cleaned_citing_abstracts.append(citing_abstracts[i])\n",
    "        cleaned_id.append(i)\n",
    "        \n",
    "        \n",
    "len(cleaned_cited_abstracts), len(cleaned_citing_abstracts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "19919c7a-6422-4a5f-bbe9-df8e640392f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "citation_contexts = dataset[\"citation_context\"].tolist()\n",
    "extracted_citation_contexts = []\n",
    "for i in cleaned_id:\n",
    "    citation_context = citation_contexts[i]\n",
    "    extracted_citation_contexts.append(citation_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "33bf19ec-e18a-4a2a-80df-d1e5749bb99b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(\"As part of an interdisciplinary project on the environmental history of the Viennese Danube, the past river landscape was reconstructed. This article describes the different types of historical sources used for the GIS-based reconstruction, the underlying methodological approach and its limitations regarding reliability and information value. The reconstruction was based on three cornerstones: (1) the available historical sources; (2) knowledge about morphological processes typical for the Austrian Danube prior to regulation; and (3) the interpretation of past hydraulic measures with respect to their effectiveness and their impact on the river's behaviour. We compiled ten historical states of the riverscape step-by-step going backwards in time to the early 16th century. After one historical situation had been completed, we evaluated its relevance for the temporally younger situations and whether corrections would have to be made. Such a regressive-iterative approach allows for permanent critical revision of the reconstructed time segments already processed. The resulting maps of the Danube floodplain from 1529 to 2010 provide a solid basis for interpreting the environmental conditions for Vienna's urban development. They also help to localise certain riverine and urban landmarks (such as river arms or bridges) relevant for the history of Vienna. We conclude that the diversity of approaches and findings of the historical and natural sciences (river morphology, hydrology) provide key synergies.\",\n",
       " 'Die Beziehungen der Kaiserstadt an der Donau zur Apenninenhalbinsel, schon seit dem Fruhhumanismus beachtlich, erfuhren wahrend der Barockzeit eine weitere Intensivierung, zumal sich mehrere Kaiser ihre Gattinnen aus dem Suden holten. Die italienische Sprache wurde indessen nicht nur am Wiener Hof gepflegt, denn Magalotti schrieb 1675: ,,Wer (in Wien) nur einen anstandigen Rock tragt, der spricht gelaufig italienisch\", und selbst die Damen bedienten sich in ihrer Unterhaltung oft dieser Sprache. So wurde Wien, wie es Heinrich Kretschmayr formuliert, im Zeitalter des Prinzen Eugen zur ,,Doppelhauptstadt von deutscher und italienischer Kultur\".1')"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_citing_abstracts[0], cleaned_cited_abstracts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "d7b829a6-5c80-4172-8b1b-5970bb25ed44",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from transformers import GPT2TokenizerFast\n",
    "\n",
    "def call_gpt(new_abstract, old_abstract):\n",
    "    openai.api_key = \"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\"\n",
    "    inputs_for_gpt = f\"\"\"\n",
    "    I have two versions of abstracts from two papers, newer and older ones:\n",
    "    ### Newer Version\n",
    "    {new_abstract}\n",
    "\n",
    "    ### Older Vesion\n",
    "    {old_abstract}\n",
    "    After reviewing the provided abstracts, please identify any improvements or advancements made in the newer paper compared to the older paper ,and highlight any new methods or techniques proposed in the newer paper that were not present in the older paper.\n",
    "\"\"\"\n",
    "    \n",
    "    # tokenizer = GPT2TokenizerFast.from_pretrained(\"gpt2\")\n",
    "    # length = len(tokenizer(inputs_for_gpt)[\"input_ids\"])\n",
    "    inputs_for_gpt = \" \".join(inputs_for_gpt.split()[:3000])\n",
    "        \n",
    "    completion = openai.ChatCompletion.create(\n",
    "         model = \"gpt-3.5-turbo\",\n",
    "         messages = [\n",
    "             {\"role\": \"user\", \"content\": inputs_for_gpt}\n",
    "         ]\n",
    "     )\n",
    "    response = completion.choices[0].message.content\n",
    "    # if \"<\"+response.split(\"<\")[-1].strip() == \"<\"+paragraph.split(\"<\")[-1].strip(): response = response \n",
    "    # else: response = response + \" <\"+paragraph.split(\"<\")[-1].strip()\n",
    "    return str(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35550530-e748-4d7b-ac32-ad53c6efe568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "responses = []\n",
    "count = 0\n",
    "for idx in range(2950, 3000): # 0-199t\n",
    "    response = call_gpt(cleaned_citing_abstracts[idx], cleaned_cited_abstracts[idx])\n",
    "    responses.append(response)\n",
    "    count += 1\n",
    "    if count%5==0: time.sleep(60)\n",
    "pd.DataFrame({\"responses\": responses}).to_csv(\"./gap_2950_2999.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "3cae0f32-99d5-4438-863e-8dd257fbf7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"citing_abstracts\": cleaned_citing_abstracts, \"cited_abstracts\": cleaned_cited_abstracts}).to_csv(\"./data/combined_abstracts_wo_res.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "3b552430-305d-436d-85ce-a101bfa8c445",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4000"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "6825a285-b104-4981-b80d-01d89bee5fb0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3032, 2939)"
      ]
     },
     "execution_count": 278,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_cited_abstracts), len(set(cleaned_cited_abstracts))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86dedac-cc0a-4d6a-a468-7605f1ad0645",
   "metadata": {},
   "source": [
    "### Add citation contexts to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "1139361f-31bf-4c8f-8515-9fcc6a5cff7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_w_meta = pd.read_csv(\"/Users/quert/Documents/GitHub/acl-research/data/abstract_w_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "fe7a5067-81bf-434e-be47-72461fb53a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "citing_abstracts = data_w_meta[\"citing_abstracts\"].tolist()\n",
    "cited_abstracts = data_w_meta[\"cited_abstracts\"].tolist()\n",
    "meta_info = data_w_meta[\"meta\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "dad2aeb1-b402-455d-b05b-c1acb67b0b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"citing_abstracts\": citing_abstracts, \"cited_abstracts\": cited_abstracts, \"meta\": meta_info, \"citation_contexts\": extracted_citation_contexts}).to_csv(\"/Users/quert/Documents/GitHub/acl-research/data/abstract_w_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c0ccd6c6-817e-4dfb-97de-90434188e21a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3032"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_w_all = pd.read_csv(\"/Users/quert/Documents/GitHub/acl-research/data/abstract_w_all.csv\")\n",
    "len(data_w_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "61d6defe-1622-4e3f-bc4e-fbedf104fc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype \n",
      "---  ------             --------------  ----- \n",
      " 0   Unnamed: 0         3032 non-null   int64 \n",
      " 1   citing_abstracts   3032 non-null   object\n",
      " 2   cited_abstracts    3032 non-null   object\n",
      " 3   meta               3032 non-null   object\n",
      " 4   citation_contexts  3032 non-null   object\n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 118.6+ KB\n"
     ]
    }
   ],
   "source": [
    "data_w_all.info()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl-venv",
   "language": "python",
   "name": "acl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
