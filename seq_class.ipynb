{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aa1743e9-b8a5-4e36-a91c-771970d1a901",
   "metadata": {},
   "source": [
    "### Combine the csvs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0367c1b6-1e9c-4b28-ba15-e687de3b85cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/acl-research/data\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Documents/GitHub/acl-research/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c07d88e-244c-4d3c-91ab-b272e00045f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"./*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fda3499d-330b-43b9-90f1-1c860568d46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3032"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_o_res = pd.read_csv(\"./combined_abstracts_wo_res.csv\")\n",
    "len(w_o_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5da12e2-b8b4-4c29-bad5-a1a162df265b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Data columns (total 3 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   Unnamed: 0        3032 non-null   int64 \n",
      " 1   citing_abstracts  3032 non-null   object\n",
      " 2   cited_abstracts   3032 non-null   object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 71.2+ KB\n"
     ]
    }
   ],
   "source": [
    "w_o_res.info()\n",
    "citing_abs = w_o_res[\"citing_abstracts\"].tolist()\n",
    "cited_abs = w_o_res[\"cited_abstracts\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ee8d7761-e645-40de-8b32-1b0ef2053b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  3032 non-null   int64 \n",
      " 1   reponses    3032 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.5+ KB\n"
     ]
    }
   ],
   "source": [
    "frame.info()\n",
    "responses = frame[\"reponses\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a916d964-2621-458b-865a-0076df530b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"citing_abstracts\": citing_abs, \"cited_abstracts\": cited_abs, \"meta\": responses}).to_csv(\"./abstract_w_meta.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae8556c-2d1d-4a1e-b4c7-590d1b63a67e",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b3bd62d8-04f2-4241-82aa-4d29a48cb5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/downloads/sequential_sentence_classification/data/CSAbstruct\n"
     ]
    }
   ],
   "source": [
    "# Check CSAbstruct data\n",
    "%cd /Users/quert/Documents/GitHub/downloads/sequential_sentence_classification/data/CSAbstruct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "de88c617-8606-46aa-bd02-6ade73b874b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "file_path = \"./dev.jsonl\"\n",
    "data = []\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    for line in file:\n",
    "        json_obj = json.loads(line)\n",
    "        data.append(json_obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "124dd530-6402-455c-89ed-62998923fbea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['In this paper we consider deterministic policy gradient algorithms for reinforcement learning with continuous actions.',\n",
       " 'The deterministic policy gradient has a particularly appealing form: it is the expected gradient of the action-value function.',\n",
       " 'This simple form means that the deterministic policy gradient can be estimated much more efficiently than the usual stochastic policy gradient.',\n",
       " 'To ensure adequate exploration, we introduce an off-policy actor-critic algorithm that learns a deterministic target policy from an exploratory behaviour policy.',\n",
       " 'We demonstrate that deterministic policy gradient algorithms can significantly outperform their stochastic counterparts in high-dimensional action spaces.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0][\"sentences\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63a1f0d8-b9be-471e-8728-4e0a7d790bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe439fd-c854-4b78-a81d-262051fb3024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data[0].keys()\n",
    "# dict_keys(['abstract_id', 'sentences', 'labels', 'confs'])\n",
    "\n",
    "# make the model to classify sentences in our data, then store them separately\n",
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\"text-classification\", model=\"typeof/distilbert_base_uncased_csabstruct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de108e2f-22e4-4e62-991a-6b4d18afb981",
   "metadata": {},
   "source": [
    "### Goals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "06e69304-34cd-4f95-acc1-ce057ca3ec67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/acl-research/data\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Documents/GitHub/acl-research/data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a001ebca-0bce-4a72-84e2-b4e24ea032cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"./abstract_w_meta.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b8310947-d872-42c3-b764-58c49cb1a2d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>citing_abstracts</th>\n",
       "      <th>cited_abstracts</th>\n",
       "      <th>meta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>Die Beziehungen der Kaiserstadt an der Donau z...</td>\n",
       "      <td>In comparing the newer and older abstracts, it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>Some hydraulic characteristics of stream chann...</td>\n",
       "      <td>Based on the comparison of the two abstracts, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>Understanding contemporary urban landscapes re...</td>\n",
       "      <td>The newer paper presents several improvements ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>Channel planform change was investigated along...</td>\n",
       "      <td>Improvements or advancements in the newer pape...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>In the relation between urban development and ...</td>\n",
       "      <td>Based on the given abstracts, there are severa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>As part of an interdisciplinary project on the...</td>\n",
       "      <td>In addition to objective climatic data, subjec...</td>\n",
       "      <td>In the newer paper compared to the older one, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Reproducibility of tender point examination in...</td>\n",
       "      <td>Background: Reproducibility concerns the degre...</td>\n",
       "      <td>In the newer paper, the improvement or advance...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>Reproducibility of tender point examination in...</td>\n",
       "      <td>We hypothesized that change in pain threshold ...</td>\n",
       "      <td>In the newer paper, there are several improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Many individual decisions are informed by dire...</td>\n",
       "      <td>In the newer paper, there have been several im...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Abstract. Social insect colonies possess remar...</td>\n",
       "      <td>In the newer paper, there are several improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Evolutionary theory predicts that animal decis...</td>\n",
       "      <td>In comparing the two abstracts, it is evident ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>We tested the decision-making abilities of emi...</td>\n",
       "      <td>Improvements/Advancements in the Newer Paper:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Abstract. When its nest is damaged, a colony o...</td>\n",
       "      <td>In the newer paper, there are several advancem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Abstract. This study views a honey bee swarm a...</td>\n",
       "      <td>In the newer version of the abstract, there ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Abstract Western scrub-jays (Aphelocoma califo...</td>\n",
       "      <td>In the newer paper, there are several improvem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Empis borealisfemales form swarms, and males c...</td>\n",
       "      <td>Comparing the two abstracts, it appears that t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Abstract.This paper examines the individual be...</td>\n",
       "      <td>Improvements or advancements made in the newer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>Foragers of the ant Lasius niger exploiting a ...</td>\n",
       "      <td>The newer version of the abstract has made sev...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>There are claims in the literature that certai...</td>\n",
       "      <td>Improvements/Advancements in the Newer Paper:\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>Decision-making animals can use slow-but-accur...</td>\n",
       "      <td>We show for the first time, to our knowledge, ...</td>\n",
       "      <td>In the newer paper, there are several improvem...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Unnamed: 0                                   citing_abstracts  \\\n",
       "0            0  As part of an interdisciplinary project on the...   \n",
       "1            1  As part of an interdisciplinary project on the...   \n",
       "2            2  As part of an interdisciplinary project on the...   \n",
       "3            3  As part of an interdisciplinary project on the...   \n",
       "4            4  As part of an interdisciplinary project on the...   \n",
       "5            5  As part of an interdisciplinary project on the...   \n",
       "6            6  Reproducibility of tender point examination in...   \n",
       "7            7  Reproducibility of tender point examination in...   \n",
       "8            8  Decision-making animals can use slow-but-accur...   \n",
       "9            9  Decision-making animals can use slow-but-accur...   \n",
       "10          10  Decision-making animals can use slow-but-accur...   \n",
       "11          11  Decision-making animals can use slow-but-accur...   \n",
       "12          12  Decision-making animals can use slow-but-accur...   \n",
       "13          13  Decision-making animals can use slow-but-accur...   \n",
       "14          14  Decision-making animals can use slow-but-accur...   \n",
       "15          15  Decision-making animals can use slow-but-accur...   \n",
       "16          16  Decision-making animals can use slow-but-accur...   \n",
       "17          17  Decision-making animals can use slow-but-accur...   \n",
       "18          18  Decision-making animals can use slow-but-accur...   \n",
       "19          19  Decision-making animals can use slow-but-accur...   \n",
       "\n",
       "                                      cited_abstracts  \\\n",
       "0   Die Beziehungen der Kaiserstadt an der Donau z...   \n",
       "1   Some hydraulic characteristics of stream chann...   \n",
       "2   Understanding contemporary urban landscapes re...   \n",
       "3   Channel planform change was investigated along...   \n",
       "4   In the relation between urban development and ...   \n",
       "5   In addition to objective climatic data, subjec...   \n",
       "6   Background: Reproducibility concerns the degre...   \n",
       "7   We hypothesized that change in pain threshold ...   \n",
       "8   Many individual decisions are informed by dire...   \n",
       "9   Abstract. Social insect colonies possess remar...   \n",
       "10  Evolutionary theory predicts that animal decis...   \n",
       "11  We tested the decision-making abilities of emi...   \n",
       "12  Abstract. When its nest is damaged, a colony o...   \n",
       "13  Abstract. This study views a honey bee swarm a...   \n",
       "14  Abstract Western scrub-jays (Aphelocoma califo...   \n",
       "15  Empis borealisfemales form swarms, and males c...   \n",
       "16  Abstract.This paper examines the individual be...   \n",
       "17  Foragers of the ant Lasius niger exploiting a ...   \n",
       "18  There are claims in the literature that certai...   \n",
       "19  We show for the first time, to our knowledge, ...   \n",
       "\n",
       "                                                 meta  \n",
       "0   In comparing the newer and older abstracts, it...  \n",
       "1   Based on the comparison of the two abstracts, ...  \n",
       "2   The newer paper presents several improvements ...  \n",
       "3   Improvements or advancements in the newer pape...  \n",
       "4   Based on the given abstracts, there are severa...  \n",
       "5   In the newer paper compared to the older one, ...  \n",
       "6   In the newer paper, the improvement or advance...  \n",
       "7   In the newer paper, there are several improvem...  \n",
       "8   In the newer paper, there have been several im...  \n",
       "9   In the newer paper, there are several improvem...  \n",
       "10  In comparing the two abstracts, it is evident ...  \n",
       "11  Improvements/Advancements in the Newer Paper:\\...  \n",
       "12  In the newer paper, there are several advancem...  \n",
       "13  In the newer version of the abstract, there ar...  \n",
       "14  In the newer paper, there are several improvem...  \n",
       "15  Comparing the two abstracts, it appears that t...  \n",
       "16  Improvements or advancements made in the newer...  \n",
       "17  The newer version of the abstract has made sev...  \n",
       "18  Improvements/Advancements in the Newer Paper:\\...  \n",
       "19  In the newer paper, there are several improvem...  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f7c5b587-5efc-4755-9456-58a784393621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/acl-research/outputs\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Documents/GitHub/acl-research/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "2aaf4081-9191-41ae-8c07-404fdf686352",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"./hyps/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame_hyps = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2f608cd3-e3b6-448f-8764-3425107c6204",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "all_files = glob.glob(\"./refs/*.csv\")\n",
    "\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "\n",
    "frame_refs = pd.concat(li, axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "7b52bc2c-9d3a-4ac1-9ad7-bee1cc418b0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3033 entries, 0 to 3032\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  3033 non-null   int64 \n",
      " 1   hyps        3017 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.5+ KB\n"
     ]
    }
   ],
   "source": [
    "frame_hyps.info()\n",
    "hyp_lst = frame_hyps[\"hyps\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d58c49e5-7a15-4ddf-9a01-cc3b23141233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3033 entries, 0 to 3032\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  3033 non-null   int64 \n",
      " 1   refs        1209 non-null   object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 47.5+ KB\n"
     ]
    }
   ],
   "source": [
    "frame_refs.info()\n",
    "refs_lst = frame_refs[\"refs\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "20007039-6f03-4cff-92d7-84337706a079",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1209"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove the instances with no refs\n",
    "keep_idx = []\n",
    "for idx in range(len(refs_lst)):\n",
    "    if refs_lst[idx]!=\"\" and str(refs_lst[idx])!=\"nan\":\n",
    "        keep_idx.append(idx)\n",
    "len(keep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "a0712d9e-1a8f-4800-a843-e814de2e6fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6, 8, 12, 13, 20, 22, 24, 25, 26, 27]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keep_idx[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "420e8ce4-63a4-403e-be54-b77c0133f509",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_hyps = [hyp_lst[idx] for idx in keep_idx]\n",
    "filtered_refs = [refs_lst[idx] for idx in keep_idx]\n",
    "assert len(filtered_hyps) == len(filtered_refs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "14f3e905-eb6d-498a-b7a6-3f8c11be3099",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/acl-research/outputs\n"
     ]
    }
   ],
   "source": [
    "# convert hyp and ref to txt\n",
    "%cd /Users/quert/Documents/GitHub/acl-research/outputs\n",
    "with open(\"./hyps.src\", \"w\") as f:\n",
    "    for hyp in filtered_hyps:\n",
    "        f.write(str(hyp).replace(\"\\n\", \"\\c\")+\"\\n\")\n",
    "with open(\"./refs.tgt\", \"w\") as f:\n",
    "    for ref in filtered_refs:\n",
    "        f.write(str(ref)+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "408335ad-355f-4f8f-a5fa-de1bed164574",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate lengths of hyps and refs\n",
    "import numpy as np\n",
    "hyp_len, ref_len = [], []\n",
    "for hyp in filtered_hyps:\n",
    "    hyp_len.append(len(str(hyp).split()))\n",
    "\n",
    "for ref in filtered_refs:\n",
    "    ref_len.append(len(str(ref).split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "8c643dbc-134f-44c3-bea1-ab7b1d322178",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(296.0, 29.0)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(hyp_len), np.median(ref_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a96dfc-ae31-40d6-bd18-e31ad6641759",
   "metadata": {},
   "source": [
    "### Split data into train and test set (70%,30%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6df0ff52-0826-47a0-9a79-b3174b01fdc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/KGG/outputs\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Documents/GitHub/KGG/outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c37b6de-ea8d-42a3-aefa-e65079436325",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyps, refs = [], []\n",
    "with open(\"./hyps.src\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        hyps.append(line.strip())\n",
    "with open(\"./refs.tgt\", \"r\") as f:\n",
    "    for line in f.readlines():\n",
    "        refs.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "566f3cec-63b8-4dfd-90eb-7217e73c10b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "start = 0\n",
    "end = 1209\n",
    "# 0-1208\n",
    "\n",
    "num_to_pick = 847\n",
    "all_ids = [idx for idx in range(start, end)]\n",
    "train_ids = list(random.sample(range(start, end), num_to_pick))\n",
    "test_ids = [ele for ele in all_ids if ele not in train_ids]\n",
    "train_ids.sort()\n",
    "test_ids.sort()\n",
    "\n",
    "# extract ids\n",
    "pd.DataFrame({\"id\": train_ids}).to_csv(\"./train_id.csv\", index=False)\n",
    "pd.DataFrame({\"id\": test_ids}).to_csv(\"./test_id.csv\", index=False)\n",
    "\n",
    "# extract train and test sets\n",
    "train_hyps = [hyps[idx] for idx in train_ids]\n",
    "train_refs = [refs[idx] for idx in train_ids]\n",
    "test_hyps = [hyps[idx] for idx in test_ids]\n",
    "test_refs = [refs[idx] for idx in test_ids]\n",
    "pd.DataFrame({\"hyp\": train_hyps, \"ref\": train_refs}).to_csv(\"./train.csv\", index=False)\n",
    "pd.DataFrame({\"hyp\": test_hyps, \"ref\": test_refs}).to_csv(\"./test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7396f446-7860-483b-a446-ffe37b6a3fb8",
   "metadata": {},
   "source": [
    "### re-structure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f92ced79-eb7f-4633-a448-2aa7053821a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/quert/Documents/GitHub/KGG\n"
     ]
    }
   ],
   "source": [
    "%cd /Users/quert/Documents/GitHub/KGG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2f651dc6-fba8-4609-9b51-7bda82982a60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3032 entries, 0 to 3031\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   Unnamed: 0  3032 non-null   int64 \n",
      " 1   background  3030 non-null   object\n",
      " 2   objective   2486 non-null   object\n",
      " 3   reference   3030 non-null   object\n",
      "dtypes: int64(1), object(3)\n",
      "memory usage: 94.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "raw_data = pd.read_csv(\"./data_updated/raw_data.csv\")\n",
    "raw_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bb62442b-e56b-4180-a215-d853480f46ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_col = raw_data[\"reference\"].tolist()\n",
    "bg_col = raw_data[\"background\"].tolist()\n",
    "obj_col = raw_data[\"objective\"].tolist()\n",
    "\n",
    "rm_na_contents = [ele for ele in reference_col if ele!=\"[]\"]\n",
    "rm_na_ids = [idx for idx in range(len(reference_col)) if reference_col[idx]!=\"[]\"]\n",
    "len(rm_na_contents), len(rm_na_ids)\n",
    "\n",
    "cleaned_bgs = [bg_col[idx] for idx in rm_na_ids]\n",
    "cleaned_objs = [obj_col[idx] for idx in rm_na_ids]\n",
    "cleaned_refs = [reference_col[idx] for idx in rm_na_ids]\n",
    "\n",
    "pd.DataFrame({\"background\": cleaned_bgs, \"objective\": cleaned_objs, \"reference\": cleaned_refs}).to_csv(\"./data_updated/data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "50d322a7-b434-4ecb-a3b1-5db8f7a1825a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into train and test sets\n",
    "import random\n",
    "\n",
    "start = 0\n",
    "end = 1217\n",
    "\n",
    "num_to_pick = 365\n",
    "\n",
    "all_ids = [idx for idx in range(1217)]\n",
    "test_ids = random.sample(range(start, end), num_to_pick)\n",
    "train_ids = [idx for idx in all_ids if idx not in test_ids]\n",
    "len(all_ids), len(train_ids), len(test_ids)\n",
    "# train\n",
    "train_bgs = [cleaned_bgs[idx] for idx in train_ids]\n",
    "train_objs = [cleaned_objs[idx] for idx in train_ids]\n",
    "train_refs = [cleaned_refs[idx] for idx in train_ids]\n",
    "# test\n",
    "test_bgs = [cleaned_bgs[idx] for idx in test_ids]\n",
    "test_objs = [cleaned_objs[idx] for idx in test_ids]\n",
    "test_refs = [cleaned_refs[idx] for idx in test_ids]\n",
    "\n",
    "\n",
    "pd.DataFrame({\"idx\": train_ids, \"background\": train_bgs, \"objective\": train_objs, \"reference\": train_refs}).to_csv(\"./data_updated/data_train.csv\", index=False)\n",
    "pd.DataFrame({\"idx\": test_ids, \"background\": test_bgs, \"objective\": test_objs, \"reference\": test_refs}).to_csv(\"./data_updated/data_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7839761-fd8e-4d78-9b91-2f4ebacf47d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare hyps and refs for scoring on `data.csv` and `data_test.csv`\n",
    "all_data = pd.read_csv(\"./data_updated/data.csv\")\n",
    "test_data = pd.read_csv(\"./data_updated/data_test.csv\")\n",
    "# all_data.info(), test_data.info()\n",
    "all_hyp = [str(all_data.iloc[idx, 0]) + \" \" + str(all_data.iloc[idx, 1]) for idx in range(len(all_data))]\n",
    "all_ref = [all_data.iloc[idx, 2] for idx in range(len(all_data))]\n",
    "all_ref = [str(ref).replace(\"['\", \"\").replace(\"']\", \"\") for ref in all_ref]\n",
    "test_hyp = [str(test_data.iloc[idx, 1]) + \" \" + str(test_data.iloc[idx, 2]) for idx in range(len(test_data))]\n",
    "test_ref = [test_data.iloc[idx, 3] for idx in range(len(test_data))]\n",
    "test_ref = [str(ref).replace(\"['\", \"\").replace(\"']\", \"\") for ref in test_ref]\n",
    "\n",
    "\n",
    "with open(\"./data_updated/data.hyp\", \"w\") as f:\n",
    "    for line in all_hyp:\n",
    "        f.write(line+\"\\n\")\n",
    "with open(\"./data_updated/data.ref\", \"w\") as f:\n",
    "    for line in all_ref:\n",
    "        f.write(str(line)+\"\\n\")\n",
    "with open(\"./data_updated/data_test.hyp\", \"w\") as f:\n",
    "    for line in test_hyp:\n",
    "        f.write(line+\"\\n\")\n",
    "with open(\"./data_updated/data_test.ref\", \"w\") as f:\n",
    "    for line in test_ref:\n",
    "        f.write(line+\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "3aaba134-d62e-4bb4-86fe-70cf52e7d36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare `merge.json` for Vicuna\n",
    "\n",
    "dataset_data = [\n",
    "    {\n",
    "        \"instruction\": \"\"\"\n",
    "    I have gathered information regarding the existing BACKGROUND and OBJECTIVE of current scholarly research. You have to return the research methodology that effectively bridges the gap between this BACKGROUND knowledge and OBJECTIVE. Remember, the output length is restricted to about 35 tokens.\n",
    "    \n",
    "    \"\"\",\n",
    "        \"input\": f\"\"\"\n",
    "        ### BACKGROUND\n",
    "        {train_bgs[idx]}\n",
    "        ### OBJECTIVE\n",
    "        {train_objs[idx]}\n",
    "        \"\"\",\n",
    "        \"output\": f\"\"\"\n",
    "        {train_refs[idx]}\n",
    "        \"\"\"\n",
    "    }\n",
    "    for idx in range(len(train_bgs))\n",
    "]\n",
    "\n",
    "with open(\"./data_updated/merge.json\", \"w\") as f:\n",
    "    json.dump(dataset_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f86f413-091d-4c61-b79e-93c36e1da2ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "acl-venv",
   "language": "python",
   "name": "acl-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
